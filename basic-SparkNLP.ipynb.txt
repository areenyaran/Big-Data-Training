{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "\n",
    "#!pip install numpy\n",
    "import numpy\n",
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning::Spark Session already created, some configs may not take.\n"
     ]
    }
   ],
   "source": [
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------+\n",
      "|text                                                                                    |\n",
      "+----------------------------------------------------------------------------------------+\n",
      "|Iam Hamed Abdelhaq. This is my firsts demo. I liv in Palestin. Please note the typos    |\n",
      "+----------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.createDataFrame([['Iam Hamed Abdelhaq. This is my firsts demo. I liv in Palestin. Please note the typos    ']]).toDF(\"text\")\n",
    "data.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentAssemble = DocumentAssembler().setInputCol('text').setOutputCol('document').setCleanupMode('shrink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceDetector = SentenceDetector().setInputCols(['document']).setOutputCol('sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizer_937404303db3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer().setInputCols(['sentence']).setOutputCol('tokens')\n",
    "tokenizer.setExceptions(['e-mail'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spellcheck_norvig download started this may take some time.\n",
      "Approximate size to download 4.2 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "checker = NorvigSweetingModel.pretrained().setInputCols(['tokens']).setOutputCol('checked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove_100d download started this may take some time.\n",
      "Approximate size to download 145.3 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "embedding = WordEmbeddingsModel.pretrained().setInputCols(['sentence', 'checked']).setOutputCol('embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ner_dl download started this may take some time.\n",
      "Approximate size to download 13.6 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "ner = NerDLModel.pretrained().setInputCols(['sentence', 'checked', 'embeddings']).setOutputCol('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = NerConverter().setInputCols(['sentence', 'checked', 'ner']).setOutputCol('chunk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#, , , , , ner, converter\n",
    "pipeline = Pipeline().setStages([documentAssemble, sentenceDetector, tokenizer, checker, embedding, ner, converter])\n",
    "model = pipeline.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|chunk                                                                                                                                                                                                                     |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[{chunk, 0, 2, Iam, {entity -> ORG, sentence -> 0, chunk -> 0}, []}, {chunk, 10, 17, Abdelhaq, {entity -> PER, sentence -> 0, chunk -> 1}, []}, {chunk, 53, 60, Palestin, {entity -> LOC, sentence -> 2, chunk -> 2}, []}]|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = model.transform(data)\n",
    "#result.select('ner.result').show(truncate = False)\n",
    "#result.select('checked.result').show(truncate = False)\n",
    "#result.select('ner.result').show(truncate = False)\n",
    "\n",
    "#result.select('chunk.result','chunk.begin','chunk.end').show(truncate = False)\n",
    "result.select('chunk').show(truncate = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
