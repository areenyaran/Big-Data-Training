Stack Overflow
Products
Search…
Areen A.'s user avatar
Areen A.
1, 1 reputation
1
Home
Questions
Tags
Saves
Users
Companies
COLLECTIVES
Explore Collectives
LABS
Discussions
TEAMS
Stack Overflow for Teams – Start collaborating and sharing organizational knowledge. 
Reducing with a bloom filter
Asked 8 years, 3 months ago
Modified 7 years, 5 months ago
Viewed 5k times
4

I would like to get a fast approximate set membership, based on a String-valued function applied to a large Spark RDD of String Vectors (~1B records). Basically the idea would be to reduce into a Bloom filter. This bloom filter could then be broadcasted to the workers for further use.

More specifically, I currently have

rdd: RDD[Vector[String]]
f: Vector[String] => String
val uniqueVals = rdd.map(f).distinct().collect()
val uv = sc.broadcast(uniqueVals)
But uniqueVals is too large to be practical, and I would like to replace it with something of smaller (and known) size, i.e. a bloom filter.

My questions:

is it possible to reduce into a Bloom filter, or do I have to collect first, and then construct it in the driver?

is there a mature Scala/Java Bloom filter implementation available that would be suitable for this?

scalaapache-sparkbloom-filter
Share
Edit
Follow
edited May 29, 2016 at 7:38
eliasah's user avatar
eliasah
39.8k1212 gold badges125125 silver badges155155 bronze badges
asked Aug 3, 2015 at 13:31
mitchus's user avatar
mitchus
4,70744 gold badges3535 silver badges7070 bronze badges
Add a comment
1 Answer
Sorted by:

Highest score (default)
10

Yes, Bloom filters can be reduced, because they have some nice properties (they are monoids). This means you can do all the aggregation operations in parallel, doing effectively just one pass over the data to construct the BloomFilter for each partition and then reduce those BloomFilters together to get a single BloomFilter that you can query for contains.

There are at least two implementations of BloomFilter in Scala and both seem mature projects (haven't actually used them in production). The first one is Breeze and the second one is Twitter's Algebird. Both contain implementations of different sketches and a lot more.

This is an example how to do that with Breeze:

import breeze.util.BloomFilter

val nums = List(1 to 20: _*).map(_.toString)
val rdd = sc.parallelize(nums, 5)

val bf = rdd.mapPartitions { iter =>
  val bf = BloomFilter.optimallySized[String](10000, 0.001)
  iter.foreach(i => bf += i)
  Iterator(bf)
}.reduce(_ | _)

println(bf.contains("5")) // true
println(bf.contains("31")) // false
Share
Edit
Follow
answered Aug 5, 2015 at 6:58
Grega Kešpret's user avatar
Grega Kešpret
11.9k66 gold badges3939 silver badges4444 bronze badges
2
One issue with this solution: It sends all the bloom filters for all partitions to the driver before merging them which can easily cause the driver to run out of memory. treeReduce(_ | _, depth=DEPTH) helps with this issue by reducing in a tree-like fashion. – 
anthonybell
 Sep 11, 2016 at 7:37
Great solution. You should also add a coalesce between the map and the reduce for better performance. As there is only one bloom filter by partition, the reduce directly sends all the bloom filters to the driver for the final merge. If there are many partitions, it can be slow or even go OOM. Coalesce with number of partition k such that k*k ~= initial number of partitions will be optimum, even if some executors are not used. – 
Boris
 Jan 7, 2018 at 22:55 
Add a comment
Your Answer
Reminder: Answers generated by Artificial Intelligence tools are not allowed on Stack Overflow. Learn more
Not the answer you're looking for? Browse other questions tagged scalaapache-sparkbloom-filter or ask your own question.
Featured on Meta
Update: New Colors Launched
We're rolling back the changes to the Acceptable Use Policy (AUP)
Temporary policy: Generative AI (e.g., ChatGPT) is banned
Beta test for short survey in banner ad slots starting on the week of...
Collectives updates: new features and ways to get started with Discussions
Hot Meta Posts
15
Disambiguate the [jetstream] tag
Related
24
Using reduceByKey in Apache Spark (Scala)
1
Spark: Filtering out aggregated data?
2
ReduceByKey on specified value element
4
Spark and BloomFilter sharing
6
Using stat.bloomFilter in Spark 2.0.0 to filter another dataframe
0
Filter with reduce in Spark
0
Training a BloomFilter on Spark with large dataset
0
Spark - Reduce List of key-value pair in Scala
0
How to model a bloom filter in Scala
0
Reduce in scala (not Spark)
Hot Network Questions
Can csquotes omit closing quotation marks?
Early 2000s series with police unit catching supernatural creatures. Main character reveals invisible monster in an episode and says "nice to see you"
Are curve secp256k1 ECDSA signatures distinguishable from random data?
Murder mystery, probably by Asimov, but SF plays a crucial role
Rearrange triple sublists
The Battleship game: Identify objects within a matrix
Is it illegal to give false information about a person to a foreign-based telemarketer?
Long table with all Mathematics columns
In Rev. Ch.5:1-5 John is weeping much because only Jesus is worthy to open the book. If John wrote Revelation why could he not look at it?
What would a mountain and desert made out of diamond, glass, or a see-through fantasy material look like?
Is it illegal to voluntarily work longer than the law allows?
What American military strategist is Yves de Gaulle referring to?
Looking for a tv series with a food processor that gave out everyone's favourite food
What is a "normal" in game development
Are owners of companies that offer public stocks without paying dividends receiving free money?
Clarification on semantics around melee attacks
more hot questions
 Question feed

STACK OVERFLOW
Questions
Help
PRODUCTS
Teams
Advertising
Collectives
Talent
COMPANY
About
Press
Work Here
Legal
Privacy Policy
Terms of Service
Contact Us
Cookie Settings
Cookie Policy
STACK EXCHANGE NETWORK
Technology
Culture & recreation
Life & arts
Science
Professional
Business
API
Data
Blog
Facebook
Twitter
LinkedIn
Instagram
Site design / logo © 2023 Stack Exchange Inc; user contributions licensed under CC BY-SA. rev 2023.11.21.1314